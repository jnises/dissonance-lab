- [ ] When developing I need to the frontend logging to be piped back to the backend and displayed in the terminal.
    - [x] Create a simple HTTP log server using axum
        - [x] Add axum and tokio dependencies for the log server
        - [x] Create a basic axum server that listens on a configurable port (e.g., 3001)
        - [x] Add a POST endpoint (e.g., `/logs`) to receive log messages from frontend
        - [x] Parse incoming JSON log data and format for terminal display
        - [x] Add CORS headers to allow requests from trunk's dev server
        - [x] Add proper error handling and graceful shutdown
    - [x] Configure Trunk to proxy log requests to the server
        - [x] Update Trunk.toml or use CLI args to proxy `/logs` path to log server
        - [x] Test that frontend can successfully send requests to `/logs` endpoint
        - [x] Verify that trunk serve and log server can run on different ports simultaneously
    - [ ] Add frontend log forwarding functionality (debug mode only)
        - [ ] Create a custom log backend that sends logs via HTTP POST to `/logs`
        - [ ] Add compile-time feature or cfg flag to enable log forwarding only in debug builds
        - [ ] Implement log batching/buffering to avoid excessive HTTP requests
        - [ ] Add fallback behavior when log server is unavailable (silent failure)
        - [ ] Ensure release builds contain no log forwarding code
    - [ ] Create development utility script using xtask
        - [ ] Set up an `xtask` command to start both the log server and trunk serve
        - [ ] Start log server in background, then start `trunk serve` with proxy config
        - [ ] Add proper process cleanup when the task is terminated
        - [ ] Include helpful output showing both server URLs and status
- [ ] piano_gui.rs: handle multi touch? is it possible to do it since this is just a single widget?
  - [ ] Research egui's MultiTouchInfo API and how to access it in the current context
    - [x] Study egui::InputState and egui::MultiTouchInfo documentation
      - Found: input.multi_touch() returns Option<MultiTouchInfo> for gestures (zoom, rotation)
      - Found: input.any_touches() returns bool for active touches
      - Found: input.has_touch_screen() returns bool for touch capability
      - Found: Event::Touch with device_id, id (TouchId), phase, pos, force for individual touches
      - Key insight: MultiTouchInfo is for gestures, but Event::Touch is for individual finger tracking
    - [x] Check if ui.input() provides access to multi-touch data
      - Yes: ui.input(|i| i.multi_touch()) for gestures
      - Yes: ui.input(|i| i.events) contains Event::Touch events for individual touches
    - [x] Investigate if egui::Sense needs to be configured differently for multi-touch
      - No: Sense only defines interaction types (HOVER, CLICK, DRAG, FOCUSABLE)
      - Multi-touch is handled through Event system, not Sense configuration
    - [x] Look at egui examples or source code for multi-touch handling patterns
      - Key finding: Need to process Event::Touch events in input.events
      - Strategy: Track TouchId -> Key mapping for individual finger tracking
      - Current issue: ui.interact() and is_pointer_button_down_on() are single-pointer
      - Solution: Process touch events directly, bypass single-pointer Response methods
  - [ ] Analyze current single-touch implementation to understand what needs to change
    - [ ] Review how is_pointer_button_down_on() works with multiple pointers
    - [ ] Understand the key_id and temp data storage mechanism
    - [ ] Document the current state tracking for mouse_pressed per key
  - [ ] Design multi-touch data structures
    - [ ] Define how to track multiple pointer IDs per key
    - [ ] Decide on data structure to map pointer IDs to pressed keys
    - [ ] Plan how to handle pointer lifecycle (press, hold, release)
  - [ ] Implement pointer tracking to handle multiple simultaneous touches
    - [ ] Replace single boolean mouse_pressed with multi-pointer tracking
    - [ ] Update key press detection to handle multiple active pointers
    - [ ] Implement pointer release detection for multi-touch
    - [ ] Handle edge cases like pointer leaving key area during touch
  - [ ] Test multi-touch functionality on mobile devices and touch screens
    - [ ] Test basic two-finger simultaneous key presses
    - [ ] Test chord playing with multiple fingers
    - [ ] Verify touch responsiveness and accuracy
    - [ ] Test edge cases like sliding fingers between keys
  - [ ] Ensure multi-touch doesn't break existing mouse and single-touch interactions
    - [ ] Verify mouse clicks still work as expected
    - [ ] Test single-touch on mobile devices
    - [ ] Ensure keyboard shortcuts (shift+click) still work
    - [ ] Test mixed input scenarios (mouse + touch simultaneously)
- [ ] Change the order of the interval displays so the bottom row shows the first pressed note when using the mouse, and the actual base when using a midi keyboard.
  - [ ] The `KeySet` type needs to keep track of the order of the keys
  - [ ] Modify PianoGui to track the chronological order of mouse key presses
  - [ ] Define what "actual base" means for MIDI keyboard input (e.g., lowest note, root note, etc.) Just assume that it is the lowest note for now.
  - [ ] Add input source tracking to distinguish between mouse and MIDI input for each pressed key. If the input modes are mixed, just do some best effort solution. No need to spend much code for this case.
  - [ ] Modify interval_display.rs to use different ordering logic based on input method
  - [ ] Update the pressed_keys data structure to include ordering/priority information
  - [ ] Test the new ordering behavior with both mouse and MIDI input
- [ ] model piano string stiffness inharmonicity
- [ ] go through the codebase looking for comments that say what has been changed. as is typical of coding agents. remove those as they are not useful longterm
