- [ ] Add a checkmark after the "midi" text in the gui when midi is correctly set up
- [ ] piano_gui.rs: handle multi touch? is it possible to do it since this is just a single widget?
  - [ ] Research egui's MultiTouchInfo API and how to access it in the current context
    - [x] Study egui::InputState and egui::MultiTouchInfo documentation
      - Found: input.multi_touch() returns Option<MultiTouchInfo> for gestures (zoom, rotation)
      - Found: input.any_touches() returns bool for active touches
      - Found: input.has_touch_screen() returns bool for touch capability
      - Found: Event::Touch with device_id, id (TouchId), phase, pos, force for individual touches
      - Key insight: MultiTouchInfo is for gestures, but Event::Touch is for individual finger tracking
    - [x] Check if ui.input() provides access to multi-touch data
      - Yes: ui.input(|i| i.multi_touch()) for gestures
      - Yes: ui.input(|i| i.events) contains Event::Touch events for individual touches
    - [x] Investigate if egui::Sense needs to be configured differently for multi-touch
      - No: Sense only defines interaction types (HOVER, CLICK, DRAG, FOCUSABLE)
      - Multi-touch is handled through Event system, not Sense configuration
    - [x] Look at egui examples or source code for multi-touch handling patterns
      - Key finding: Need to process Event::Touch events in input.events
      - Strategy: Track TouchId -> Key mapping for individual finger tracking
      - Current issue: ui.interact() and is_pointer_button_down_on() are single-pointer
      - Solution: Process touch events directly, bypass single-pointer Response methods
  - [x] Analyze current single-touch implementation to understand what needs to change
    - [x] Review how is_pointer_button_down_on() works with multiple pointers
      - is_pointer_button_down_on() only detects single primary pointer, not individual touch IDs
      - Returns true if any pointer is down on the widget, but doesn't distinguish between multiple pointers
      - This is the core limitation preventing multi-touch functionality
    - [x] Understand the key_id and temp data storage mechanism
      - Each key gets unique key_id using ui.id().with(format!("{color}{key}"))
      - temp data stores boolean mouse_pressed state per key_id
      - Current system works well for single pointer but needs extension for multiple TouchId tracking
    - [x] Document the current state tracking for mouse_pressed per key
      - Lines 116-131: Press detection when is_pointer_button_down_on() && !mouse_pressed
      - Release detection when !is_pointer_button_down_on() && mouse_pressed
      - State stored/retrieved via ui.data().get_temp::<bool>(key_id)
      - Single boolean per key limits to one active pointer per key
  - [x] Design multi-touch data structures
    - [x] Define how to track multiple pointer IDs per key
      - Replace single boolean with HashSet<TouchId> per key to track all active pointers
      - Key is considered pressed if HashSet is non-empty
      - Allows multiple fingers to press same key simultaneously
    - [x] Decide on data structure to map pointer IDs to pressed keys
      - Primary: HashMap<KeyId, HashSet<TouchId>> - tracks which pointers are on each key
      - Secondary: HashMap<TouchId, KeyId> - reverse lookup to find which key a pointer is on
      - Use egui::TouchId for touch identification (wraps u64)
      - Mouse input can use special TouchId::from_u64(0) for compatibility
    - [x] Plan how to handle pointer lifecycle (press, hold, release)
      - Press: TouchId enters key area, add to key's HashSet, send Action::Pressed if key becomes newly active
      - Hold: TouchId remains in key area, no action needed
      - Release: TouchId leaves key area or touch ends, remove from HashSet, send Action::Released if key becomes inactive
      - Drag between keys: Remove from old key's set, add to new key's set, handle press/release actions accordingly
  - [ ] Implement pointer tracking to handle multiple simultaneous touches
    - [x] Replace single boolean mouse_pressed with multi-pointer tracking
      - Implemented PointerId enum to distinguish Mouse vs Touch(u64) pointers
      - Replaced single boolean with HashSet<PointerId> per key for tracking active pointers
      - Added HashMap<PointerId, Id> for reverse lookup (pointer -> key mapping)
      - Mouse uses PointerId::Mouse, touches use PointerId::Touch(id.0) from TouchId
    - [x] Update key press detection to handle multiple active pointers
      - Key press detected when HashSet transitions from empty to non-empty
      - Key release detected when HashSet transitions from non-empty to empty
      - Handles both mouse (via is_pointer_button_down_on) and touch events (via Event::Touch)
    - [x] Implement pointer release detection for multi-touch
      - Touch events processed for Start/Move/End/Cancel phases
      - Proper cleanup when touches end or are cancelled
      - Mouse release handled via !is_pointer_button_down_on transition
    - [x] Handle edge cases like pointer leaving key area during touch
      - Touch move events check if pointer is still within key_rect
      - Automatic removal from old key when touch moves to new key
      - Proper cleanup of pointer mappings when touches leave key areas
  - [x] use wmidi::Note rather than usize to represent semitones in piano_gui.rs
    - Replaced HashMap<usize, HashSet<PointerId>> with HashMap<wmidi::Note, HashSet<PointerId>> for tracking which pointers are holding each key. This is more efficient since wmidi::Note is internally a u8, compared to usize which is pointer-sized. Added configurable octave support so the piano GUI can display any octave (0-9) rather than being hardcoded to a single octave. Added helper function semitone_to_note_in_octave() for clean conversion. The note_to_semitone() function retains the % 12 operation only for UI purposes where semitone indices (0-11) are still needed for the BitArray operations.
  - [ ] Create a type that represents a semitone in piano_gui.rs. That is, a value between 0 and 11. And use that instead of usize.
  - [ ] Make sure you add `debug_assert` where it makes sense in piano_gui.rs
  - [ ] Test multi-touch functionality on mobile devices and touch screens
    - [ ] Test basic two-finger simultaneous key presses
    - [ ] Test chord playing with multiple fingers
    - [ ] Verify touch responsiveness and accuracy
    - [ ] Test edge cases like sliding fingers between keys
  - [ ] Ensure multi-touch doesn't break existing mouse and single-touch interactions
    - [ ] Verify mouse clicks still work as expected
    - [ ] Test single-touch on mobile devices
    - [ ] Ensure keyboard shortcuts (shift+click) still work
    - [ ] Test mixed input scenarios (mouse + touch simultaneously)
- [ ] Make the console output from the audio worklet also forward back to the dev server. perhaps we need to have the audio worklet log using a message instead of straight to console
- [ ] Try increasing the reverb to hear how it sounds
- [ ] Could the midi input callback be moved out of the rust code to make it lower latency?
- [ ] Change the order of the interval displays so the bottom row shows the first pressed note when using the mouse, and the actual base when using a midi keyboard.
  - [ ] The `KeySet` type needs to keep track of the order of the keys
  - [ ] Modify PianoGui to track the chronological order of mouse key presses
  - [ ] Define what "actual base" means for MIDI keyboard input (e.g., lowest note, root note, etc.) Just assume that it is the lowest note for now.
  - [ ] Add input source tracking to distinguish between mouse and MIDI input for each pressed key. If the input modes are mixed, just do some best effort solution. No need to spend much code for this case.
  - [ ] Modify interval_display.rs to use different ordering logic based on input method
  - [ ] Update the pressed_keys data structure to include ordering/priority information
  - [ ] Test the new ordering behavior with both mouse and MIDI input
- [ ] model piano string stiffness inharmonicity
- [ ] go through the codebase looking for comments that say what has been changed. as is typical of coding agents. remove those as they are not useful longterm
- [ ] Calculate dissonances using critical bands theory instead.
    - This would allow us to calculate the dissonance of entire chords
    - how do we handle the fact that we only show a single octave? just force the calculation to happen on a single central octave?
    - can critical bands theory be made octave normalized?
    - does critical bands theory care about the root? do we need to know which note is the root? can the overtones be extended downwards?
- [ ] The dissonance of the currently held notes should show somewhere prominent
- [ ] We only need one row of dissonances that shows what dissonance a new note would result in.
    - for the second note we show the same as we currently do
    - for more notes we show what chord they would result in
- [ ] Make `shift` behave like a sustain pedal. We want almost infinite sustain to allow the user to hear chord dissonances.
